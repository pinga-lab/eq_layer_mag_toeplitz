\section{Methodology}

%======================================================================================
\subsection*{The total-field anomaly}
%======================================================================================

The Earth's magnetic field is commonly divided in three parts: main field, crustal field and external field. The main field is generated in the outter core in a process of self-sustaining dynamo, the crustal field is generated by magnetic bodies in the litosphere and the external field is generated by electrical currents in the ionosphere and magnetosphere. For exploration geophysics, the crustal field is the object of study, which makes the separation of this data from the acquisition dataset a very important step.

The combination of the main field and crustal field is known as internal field or total-field. Taking the difference between the main field given by a model (e.g. IGRF) and this internal field, at the same location, we have the total-field anomaly.

Let $(x_i, y_i, z_i), i =  1,2,3,...N$, be a observed dataset in a region considering a right-handed Cartesian coordinate system with the $x$-axis pointing north, $y$-axis pointing east and $z$-axis pointing downward. The total-field anomaly at the $i$th observation can be approximated to:
\begin{equation}
	\Delta T(x_i, y_i, z_i) = \hat{\mathbf{F}}^{\top} \mathbf{B}(x_i, y_i, z_i) \: ,
	\label{eq:tfanomaly}
\end{equation}
where, $\mathbf{B}(x_i, y_i, z_i)$ is the crustal field, $\hat{\mathbf{F}}^{\top}$ is the transposed unitary vector with the main field directions, with $\hat{\mathbf{F}}$ described as:
\begin{equation}
	\hat{\mathbf{F}} = \left[
	\begin{array}{c}
		F_x \\
		F_y \\
		F_z
	\end{array} \right] = 
	\left[
	\begin{array}{c}
		\cos(I_{0}) \, \cos(D_{0}) \\
		\cos(I_{0}) \, \sin(D_{0}) \\
		\sin(I_{0})
	\end{array} \right],
	\label{eq:unit_vector_F}
\end{equation}
where $I_{0}$ is the inclination and $D_{0}$ the declination of the main field, respectively.

Considering a uniform magnetized body with volume $v$ and a total magnetization vector $\mathbf{m}$, the induced magnetic field is:
\begin{equation}
	\mathbf{B}(x_i, y_i, z_i) = c_{m} \, \frac{\mu_{0}}{4\pi} \: \mathbf{M}(x_i, y_i, z_i) \: 
	\mathbf{m} \: ,
	\label{eq:induction-general}
\end{equation}
where, $\mu_{0} = 4\pi \, 10^{-7}$ H/m is the magnetic constant, 
$c_{m} = 10^{9}$ is a constant that transforms the induced magnetic field from Tesla (T) to nanotesla (nT) and 
$\mathbf{M}(x_i, y_i, z_i)$ is a $3 \times 3$ matrix given by:
\begin{equation}
	\mathbf{M}(x_i, y_i, z_i) =
	\left[
	\begin{array}{ccc}
		\partial_{xx} \phi(x_i,y_i,z_i) & \partial_{xy} \phi(x_i,y_i,z_i) & 
		\partial_{xz} \phi(x_i,y_i,z_i) \\
		\partial_{xy} \phi(x_i,y_i,z_i) & \partial_{yy} \phi(x_i,y_i,z_i) & 
		\partial_{yz} \phi(x_i,y_i,z_i) \\
		\partial_{xz} \phi(x_i,y_i,z_i) & \partial_{yz} \phi(x_i,y_i,z_i) & 
		\partial_{zz} \phi(x_i,y_i,z_i)
	\end{array}
	\right] \: ,
	\label{eq:M}
\end{equation}
where, $\partial_{\alpha\beta} \phi(x_i,y_i,z_i)$ with $\alpha = x, y, z$ and 
$\beta = x, y, z$, are the second derivatives of the function $\phi(x_i,y_i,z_i)$
with respect to $x$, $y$ and $z$:

\begin{equation}
	\phi(x_i,y_i,z_i) = \int\int\limits_{v}\int \frac{1}{r} \: dv,
	\label{eq:phi}
\end{equation}
where the function $\dfrac{1}{r}$ is given by:

\begin{equation}
	\dfrac{1}{\sqrt{(x_i - x_j)^{2} + 
			(y_i - y_j)^{2} + (z_i - z_j)^{2}}} \,
	\label{eq:r}
\end{equation}
and $x_j, y_j, z_j$ are the $j$th Cartesian coordinates within the volume elements of the magnetized body with volume $v$, where the integral (equation \ref{eq:phi}) is conducted.

Rewriting the equation \ref{eq:tfanomaly} using the magnetic induction given by equation \ref{eq:induction-general} the total-field anomaly $\Delta T(x, y, z)$ is given by:
\begin{equation}
\Delta T(x_i, y_i, z_i) = c_{m} \, \frac{\mu_{0}}{4\pi} \, m \: \hat{\mathbf{F}}^{\top} 
\mathbf{M}(x_i, y_i, z_i) \: \hat{\mathbf{m}} \: ,
\label{eq:tfanomaly-general}
\end{equation}
where $m$ is the magnetization intensity and $\hat{\mathbf{m}}$ is the directional unitary vector.

%======================================================================================
\subsection*{Equivalent layer for magnetic data}
%======================================================================================

Grounded on the equivalent layer principle it is possible to calculate the total-field anomaly $\Delta T(x_i, y_i, z_i)$ (equation \ref{eq:tfanomaly-general}) with the convolution between the harmonic function and the physical property:
\begin{equation}
\Delta T(x_{i}, y_{i}, z_{i})
= \int \limits_{-\infty}^{+\infty}
\int \limits_{-\infty}^{+\infty}
p(x_j, y_j, z_{c}) \,
\left[ c_{m} \, \frac{\mu_{0}}{4\pi} \,
\hat{\mathbf{F}}^{\top} \mathbf{H} \, 
\hat{\mathbf{h}} \right] \,
dx \, dy \: ,
\label{eq:tf-p-continuous-mag-positive}
\end{equation}
where $z_c$ is a constant representing the depth of the equivalent layer with $z_i < z_c$. The unitary vector $\hat{\mathbf{h}}$ is the magnetization directions of the equivalent sources over the layer:
\begin{equation}
\hat{\mathbf{h}} = \left[
\begin{array}{c}
{h}_x \\
{h}_y \\
{h}_z
\end{array} \right] = 
 \left[
\begin{array}{c}
\cos(I) \, \cos(D) \\
\cos(I) \, \sin(D) \\
\sin(I)
\end{array}
\right] \: ,
\label{eq:h_hat}
\end{equation}
where $I$ and $D$ are, respectively, the inclination and declination of the equivalent sources, $\mathbf{H}$ is a $3 \times 3$ matrix that contains the second derivatives in relation to the observed Cartesian coordinates $x, y, z$ as presented in equation \ref{eq:r}:
\begin{equation}
\mathbf{H} =
\left[
\begin{array}{ccc}
\partial_{xx} \frac{1}{r} & 
\partial_{xy} \frac{1}{r} & 
\partial_{xz} \frac{1}{r} \\
\partial_{xy} \frac{1}{r} & 
\partial_{yy} \frac{1}{r} & 
\partial_{yz} \frac{1}{r} \\
\partial_{xz} \frac{1}{r} & 
\partial_{yz} \frac{1}{r} & 
\partial_{zz} \frac{1}{r}
\end{array}
\right] \: =
\left[
\begin{array}{ccc}
H_{xx} & 
H_{xy} & 
H_{xz} \\
H_{xy} & 
H_{yy} & 
H_{yz} \\
H_{xz} & 
H_{yz} & 
H_{zz}
\end{array}
\right] \: ,
\label{eq:Hi}
\end{equation}
and the physical property $p(x_j, y_j, z_{c})$ represents the magnetic dipole moment distribution over the layer and has unit of $Am^2$.

Discretizing equation \ref{eq:tf-p-continuous-mag-positive} we get:
\begin{equation}
\Delta T(x_{i}, y_{i}, z_{i}) = \sum_{j=1}^{M} p_j a_{ij}\: ,
\label{eq:integral-sum_mag}
\end{equation}
where $j = 1,2,3,...,M$ are the equivalent sources discretized and distributed across the layer and $a_{ij}$ is given by:
\begin{equation}
a_{ij}
= c_{m} \, \frac{\mu_{0}}{4\pi} \, \hat{\mathbf{F}}^{\top} \mathbf{H}_{ij} \: \hat{\mathbf{h}} \: .
\label{eq:aij_mag}
\end{equation}
Equation \ref{eq:integral-sum_mag} can be written as:
\begin{equation}
\mathbf{d}(\mathbf{p}) = \mathbf{A} \mathbf{p} \: ,
\label{eq:predicted-data-vector_mag}
\end{equation}
where $\mathbf{d}(\mathbf{p})$ is the vector of total-field anomaly, $\mathbf{A}$ is a matrix containing the elements given by equation \ref{eq:aij_mag}, also known as the sensitivity matrix and $\mathbf{p}$ is the vector containing the dipole moments of each equivalent source. By using the normal equations:
\begin{equation}
	\mathbf{A}^{\top}\mathbf{A}{\mathbf{p}} = 
	\mathbf{A}^{\top} \mathbf{d}^{o} \:
	\label{eq:normal-equations}
\end{equation} 
which is a conventional manner of solving linear systems, the estimative of the dipole moment parameters vector can be calculated from the total-field anomaly as:
\begin{equation}
\hat{\mathbf{p}} = \left( \mathbf{A}^{\top}\mathbf{A} %+ 
%\mu \, \mathbf{I} 
\right)^{-1}
\mathbf{A}^{\top} \mathbf{d}^{o} \:
\label{eq:estimated-p-parameter-space}
\end{equation}
where $\mathbf{d}^{o}$ is the observed total-field anomaly. Equation \ref{eq:estimated-p-parameter-space} will be referenced throughout this work as the classical method for solving the equivalent layer.

%======================================================================================
\subsection{Conjugate Gradient Least Square method (CGLS)}
%======================================================================================

As an alternative from the clasical method of parameter estimative, the conjugate gradient (CG) is a well-known iterative method for solving linear systems with symmetric positive definite matrices. By minimizing the quadratic form:
\begin{equation}
\, \Phi(\mathbf{p}) = \frac{1}{2} \, \mathbf{p}^{\top} \, \mathbf{A} \, \mathbf{p} \,
- \mathbf{{d}^{o}}^{\top} \, \mathbf{p}\: ,
\label{eq:estimated-p-cg}
\end{equation}
it is possible to solve the system by constructing a basis of conjugate directions $c \in R^N$ \citep{aster2018parameter}. As we are solving a general least square problem and matrix $\mathbf{A}$ (equation \ref{eq:aij_mag}) is not symmetric, instead we minimize:
\begin{equation}
\, || \mathbf{A} \, \mathbf{p} - \mathbf{d}^o||_2 \: ,
\label{eq:estimated-p-cgls}
\end{equation}
by applying the conjugate gradient to the normal equations (equation \ref{eq:normal-equations}).

In theory, this method is bound to converge at $N$ iterations maximum, but in a later part of this work we show with numerical results that the convergence is much faster for the linear system we are solving.

A pseudocode for the CGLS method follows:

\begin{algorithm}[H]
	Input: $\mathbf{A} \in R^{N \times M} $ and $\mathbf{d}^o \in R^N$.
	
	Output: Estimative of parameter vector $\hat{\mathbf{p}}$.
	
	Let $it = 0$, $\hat{\mathbf{p}}^{(0)} = {\mathbf{0}}$, $\mathbf{c}^{(-1)} = {\mathbf{0}}$, $\beta_0 = 0$, $\mathbf{s}^{(0)} = \mathbf{d}^{o} - \mathbf{A} \hat{\mathbf{p}}^{(0)}$ and $\mathbf{r}^{(0)} = \mathbf{A}^{\top} \mathbf{s}^{(0)}$.
	
	1 - If $it > 0$, let $\beta_{(it)} = \dfrac{{\mathbf{r}^{(it)}}^{\top} \, \mathbf{r}^{(it)}} {{\mathbf{r}^{(it - 1)}}^{\top} \, \mathbf{r}^{(it - 1)}}$
	
	2 - $\mathbf{c}^{(it)} = \mathbf{r}^{(it)} + \beta_{(it)} \, \mathbf{c}^{(it - 1)}$.
	
	3 - $\alpha_{(it)} = \dfrac{{||\mathbf{r}^{(it)}||^2_2}}{({\mathbf{c}^{(it)}}^{\top} \, \mathbf{A}^{\top})(\mathbf{A} \, \mathbf{c}^{(it)})}$.
	
	4 - $\hat{\mathbf{p}}^{(it + 1)} = \hat{\mathbf{p}}^{(it)} + \alpha_{(it)} \, \mathbf{c}^{(it)}$.
	
	5 - $\mathbf{s}^{(it + 1)} = \mathbf{s}^{(it)} - \alpha_{(it)} \, \mathbf{A} \, \mathbf{c}^{(it)}$.
	
	6 - $\mathbf{r}^{(it + 1)} = \mathbf{A}^{\top} \, \mathbf{s}^{(it + 1)}$.
	
	7 - $it = it + 1$.
	
	8 - Repeat previous steps until convergence.
	
	\caption{Conjugate Gradient Least Square pseudocode \citep[][ p. 166]{aster2018parameter}.}
\label{al:cgls-algorithm}
\end{algorithm}

Different from the classical least-square solution (equation \ref{eq:estimated-p-parameter-space}), the CGLS solution (Algorithm 1) requires neither inverse matrix nor matrix-matrix product.The CGLS method only requires: one matrix-vector multiplication out of the loop and two matrix-vector multiplications, in steps 3 and 6, at each iteration. 

In this work, we will reduce the computational cost of the equivalent layer by substituting exactly these two matrix-vector products with a much more efficient algorithm.

%======================================================================================
\subsection{Conjugate Gradient Least Square method convergence criteria}
%======================================================================================

In theory, this method is bound to converge at $N$ iterations maximum, but in a later part of this work we show with numerical results that the convergence is much faster for the linear system we are solving. Setting a minimum tolerance of the residuals is a good option to carry out this algorithm efficiently and still obtaining very good results. Another possibility is to set an invariance to the euclidian norm of residuals between iteractions, wich would increase algorithm runtime, but with smaller residuals. We chose the first option, as we achieve satisfatory results.

%======================================================================================
\subsection{Non-symmetric Block-Toeplitz Toeplitz-Block structure of matrix $\mathbf{A}$}
%======================================================================================

Let us consider that the observed total-field anomaly is located on an $N_x \times N_y$ regular grid of points spaced by $\Delta_x$ and $\Delta_y$ along the $x$- and $y$-directions, respectively.
The notation used in this work will be the same as the one presented in \cite{takahashi2020convolutional}, where the authors described the structure of the symmetric Block-Toeplitz Toeplitz-Block matrix of the gravimetric equivalent layer. Here, we also establish a relation between the pair of \emph{matrix coordinates} $(x_i, y_i)$, $i = 1, ..., N$ or $(x_j, y_j)$, $j = 1, ..., M = N $ and a pair of \emph{grid coordinates} $(x_k, y_l)$ given as:
\begin{equation}
x_{i} \equiv x_{k} = x_{1} + \left[ k(i) - 1 \right] \, \Delta x \: , 
\label{eq:xi}
\end{equation}
and
\begin{equation}
y_{i} \equiv y_{l} = y_{1} + \left[ l(i) - 1 \right] \, \Delta y \: .
\label{eq:yi}
\end{equation}
In a $x$-\textit{oriented grid} the indices $i$ (or $j$) relate as integer functions of $k$ and $l$ by:
\begin{equation}
i(k, l) = (l - 1) \, N_{x} + k \: ,
\label{eq:i-x-oriented}
\end{equation}
\begin{equation}
l(i) = \Bigg\lceil \frac{i}{N_{x}} \Bigg\rceil
\label{eq:l-x-oriented}
\end{equation}
and
\begin{equation}
k(i)  = i - \Bigg\lceil \frac{i}{N_{x}} \Bigg\rceil N_{x} + N_{x} \: .
\label{eq:k-x-oriented}
\end{equation}
For  $y$-\textit{oriented grid} they are given by:
\begin{equation}
i(k, l) = (k - 1) \, N_{y} + l \: ,
\label{eq:i-y-oriented}
\end{equation}
\begin{equation}
k(i) = \Bigg\lceil \frac{i}{N_{y}} \Bigg\rceil
\label{eq:k-y-oriented}
\end{equation}
and
\begin{equation}
l(i) = i - \Bigg\lceil \frac{i}{N_{y}} \Bigg\rceil N_{y} + N_{y} \: ,
\label{eq:l-y-oriented}
\end{equation}
where in equations \ref{eq:l-x-oriented} to \ref{eq:l-y-oriented}, $\lceil .\rceil$ is the celing function.
Figure \ref{fig:methodology} shows an example of a grid $N_{x} \times N_{y}$, where $N_{x} = 4$ and $N_{y} = 3$ demonstrating the relation between the \emph{matrix coordinates} with $k(i)$ and $l(i)$ depending on the orientation of the grid.

The $N \times M$ sensitivity matrix  $\mathbf{A}$ (equation \ref{eq:aij_mag}) can be represented as a grid of $Q \times Q$ blocks $\mathbf{A}^q$, $q = -Q+1,...,0,..., Q-1$. Each block  $\mathbf{A}^q$ has $P \times P$ elements $a^{q}_p$ where $p = -P+1^,...,0,...,P-1$

In a $x$-\textit{oriented grid} $q$ and $p$ give the number of blocks ($Q = N_{y}$) and the number of elements of each block ($P = N_{x}$). They can be defined by the integer functions:
\begin{equation}
q(i, j) = \; l(i) - l(j)
\label{eq:q-x-oriented}
\end{equation}
and
\begin{equation}
p(i, j) = \; k(i) - k(j) \: ,
\label{eq:p-x-oriented}
\end{equation}
where equations \ref{eq:l-x-oriented} and \ref{eq:k-x-oriented} describe $l(i)$ and $l(j)$ and $k(i)$ and $k(j)$, respectively. When using $y$-oriented grids, $q$ and $p$ still define the number of block and block elements, but $Q = N_{x}$ and $P = N_{y}$. Moreover, the integer functions changes to:
\begin{equation}
q(i, j) = \; k(i) - k(j) 
\label{eq:q-y-oriented}
\end{equation}
and
\begin{equation}
p(i, j) = \; l(i) - l(j) \: ,
\label{eq:p-y-oriented}
\end{equation}
where equation \ref{eq:k-y-oriented} now defines $k(i)$ and $k(j)$ and equation \ref{eq:l-y-oriented} defines $l(i)$ and $l(j)$. Note that equations \ref{eq:q-x-oriented}, \ref{eq:p-x-oriented}, \ref{eq:q-y-oriented} and \ref{eq:q-y-oriented} differs from the ones presented in \cite{takahashi2020convolutional} by the absence of the module.

In both $x$- or $y$-\textit{orientation}, matrix $\mathbf{A}$ (equation \ref{eq:aij_mag}) can be rewritten by the indices $q = -Q + 1,...,0,..., Q-1$ defining the number of its blocks:
\begin{equation}
\mathbf{A} = \begin{bmatrix}
\mathbf{A}^{0}   & \mathbf{A}^{-1} & \cdots          & \mathbf{A}^{-Q+1} \\
\mathbf{A}^{1}   & \mathbf{A}^{0}  & \mathbf{A}^{-1} & \vdots           \\ 
\vdots           & \mathbf{A}^{1}  & \ddots          & \mathbf{A}^{-1}   \\
\mathbf{A}^{Q-1} & \cdots          & \mathbf{A}^{1}  & \mathbf{A}^{0}                 
\end{bmatrix}_{N \times N} \: ,
\label{eq:BTTB_A}
\end{equation}
and by indice $p$, where each block has $P \times P$ elements $a^{q}_{p}$, $p = -P + 1,..., 0, \dots, P - 1$:
\begin{equation}
\mathbf{A}^{q} = \begin{bmatrix}
a^{q}_{0}   & a^{q}_{-1} & \cdots     & a^{q}_{-P+1} \\
a^{q}_{1}   & a^{q}_{0}  & a^{q}_{-1} & \vdots           \\ 
\vdots      & a^{q}_{1}  & \ddots     & a^{q}_{-1}   \\
a^{q}_{P-1} & \cdots     & a^{q}_{1}  & a^{q}_{0}                 
\end{bmatrix}_{P \times P} \: ,
\label{eq:Aq_block}
\end{equation}
In general, matrix $\mathbf{A}$ (equation \ref{eq:aij_mag}) is a non-symmetric BTTB, i.e., its blocks are non-symmetric ($\mathbf{A}^{-Q+1} \neq \mathbf{A}^{Q-1} $) and its elements also are non-symmetric ($a^{q}_{-1} \neq a^{q}_{1}$). Depending on specific values of the main field direction and the equivalent sources magnetization directions, matrix $\mathbf{A}$ can assume other structures, for example, when $\hat{\mathbf{F}} = [0, 0, 1]$ and $\hat{\mathbf{h}} = [0, 0, 1]$ it becomes symmetric. In this work, we are considering the more commom situation for the matrix $\mathbf{A}$.

Also differently for the symmetric sensitivity matrix described by \cite{takahashi2020convolutional}, the non-symmetric BTTB matrix cannot be reconstructed only by its first column. The construction of the matrix $\mathbf{A}$ (equation \ref{eq:aij_mag}) needs four columns: the first and last columns of the first column of blocks and the first and last columns of the last column of blocks. This has a physical implication in the equivalent layer which is not possible to use only one equivalent source to reprduce all elements of matrix $\mathbf{A}$, such as in the gravity case as demonstrared by \cite{takahashi2020convolutional}. Rather, in the magnetic case it takes four equivalent sources positioned at each corner of the equivalent layer. Figure \ref{fig:4_equivalent_sources} shows the positioning of the equivalent sources in a regular grid $N_x = 4$ $N_y = 3$ necessary to calculate the four columns capable of recover the matrix $\mathbf{A}$.

In this work, we propose a different approach, by calculating the first column of all six different components of second derivatives matrices from $\mathbf{H}_{ij}$ (equation \ref{eq:Hi}). These matrices are, in fact, symmetrics or skew-symmetrics BTTBs, meaning that the first column has all elements of each matrix.

By substituting equations \ref{eq:unit_vector_F}, \ref{eq:h_hat} and \ref{eq:Hi} into equation \ref{eq:aij_mag}, it is possible to describe each element of the sensitivity matrix by the second derivative components of $\mathbf{H}_{ij}$:
\begin{equation}
\begin{split}
a_{ij} = c_{m} \, \frac{\mu_{0}}{4\pi} \, (F_x H_{xx} + F_y H_{xy} + F_z H_{xz}) \, h_x  \, + \\
(F_x H_{xy} + F_y H_{yy} + F_z H_{yz}) \, h_y  \, + \\
(F_x H_{xz} + F_y H_{yz} + F_z H_{zz}) \, h_z \: .
\end{split}
\label{eq:aij_mag_expand}
\end{equation}

If we consider that $c_{m} \, \frac{\mu_{0}}{4\pi}$, $\hat{\mathbf{F}}$ (equation \ref{eq:unit_vector_F}) and $\hat{\mathbf{h}}$ (equation\ref{eq:h_hat}) are constants multiplying the second derivatives $\mathbf{H}$ (equation \ref{eq:Hi}), the sensitivity matrix $\mathbf{A}$ (equation \ref{eq:aij_mag}) is purely the sum of the components $H_{xx} + H_{xy} + H_{xz} + H_{xy} + H_{yy} + H_{yz} + H_{xz} + H_{yz} + H_{zz}$ multiplied by the respectives constants of each component. Thus, despite $\mathbf{A}$ not being a symmetric BTTB matrix, it can be in fact, written by calculating only the first column of these components.
In the next few sections we will describe each component $\mathbf{H}$ as its own matrix.

%======================================================================================
\subsection{Structure of matrices components $\mathbf{H_{xx}}$, $\mathbf{H_{yy}}$ and $\mathbf{H_{zz}}$}
%======================================================================================

We can describe the elements of $\mathbf{H_{xx}}$, $\mathbf{H_{yy}}$ and $\mathbf{H_{zz}}$ by substituting equations \ref{eq:xi} and \ref{eq:yi} in equation \ref{eq:Hi}  as:
\begin{equation}
h^{xx}_{ij} = \frac{-1}{ \left[ 
		\left( \Delta k_{ij} \, \Delta x \right)^{2} + 
		\left( \Delta l_{ij} \, \Delta y \right)^{2} + 
		\left( \Delta z \right)^{2} \right]^{\frac{3}{2}}} + 
		\frac{3 (\Delta k_{ij} \, \Delta x )^{2}}{\left[ 
		\left( \Delta k_{ij} \, \Delta x \right)^{2} + 
		\left( \Delta l_{ij} \, \Delta y \right)^{2} + 
		\left( \Delta z \right)^{2} \right]^{\frac{5}{2}}} \: ,
\label{eq:hxx_mag}
\end{equation}

\begin{equation}
	h^{yy}_{ij} = \frac{-1}{ \left[ 
		\left( \Delta k_{ij} \, \Delta x \right)^{2} + 
		\left( \Delta l_{ij} \, \Delta y \right)^{2} + 
		\left( \Delta z \right)^{2} \right]^{\frac{3}{2}}} + 
	\frac{3 (\Delta l_{ij} \, \Delta y )^{2}}{\left[ 
		\left( \Delta k_{ij} \, \Delta x \right)^{2} + 
		\left( \Delta l_{ij} \, \Delta y \right)^{2} + 
		\left( \Delta z \right)^{2} \right]^{\frac{5}{2}}} \: 
	\label{eq:hyy_mag}
\end{equation}
and
\begin{equation}
	h^{zz}_{ij} = \frac{-1}{ \left[ 
		\left( \Delta k_{ij} \, \Delta x \right)^{2} + 
		\left( \Delta l_{ij} \, \Delta y \right)^{2} + 
		\left( \Delta z \right)^{2} \right]^{\frac{3}{2}}} + 
	\frac{3 (\Delta z )^{2}}{\left[ 
		\left( \Delta k_{ij} \, \Delta x \right)^{2} + 
		\left( \Delta l_{ij} \, \Delta y \right)^{2} + 
		\left( \Delta z \right)^{2} \right]^{\frac{5}{2}}} \: ,
	\label{eq:hzz_mag}
\end{equation}
where $\Delta z = z_j - z_i$, $\Delta k_{ij} =k(i) - k(j)$ (equations \ref{eq:k-x-oriented} or \ref{eq:k-y-oriented}) and $\Delta l_{ij} = l(i) - l(j)$ (equations \ref{eq:l-x-oriented} or \ref{eq:l-y-oriented}).
The principal components $\mathbf{H_{xx}}$, $\mathbf{H_{yy}}$ and $\mathbf{H_{zz}}$ (equations \ref{eq:hxx_mag}, \ref{eq:hyy_mag} and \ref{eq:hzz_mag}, respectively) of matrix $\mathbf{H}$ (equation \ref{eq:Hi}) are symmetric-Block-Toeplitz symmetric-Toeplitz-Block matrices. This means that $\mathbf{H_{xx}}$, $\mathbf{H_{yy}}$ and $\mathbf{H_{zz}}$ are Toeplitz and symmetric by its blocks and each of the blocks are symmetric Toeplitz matrices. 
For example, $\mathbf{H_{xx}}$ can be described by the \textit{block indice} $q$ that represent the block diagonals of this matrix as a grid of $Q \times Q$ blocks $\mathbf{H}^{q}_\mathbf{xx}$, $q = 0, \dots, Q - 1$:
\begin{equation}
\mathbf{H_{xx}} = \begin{bmatrix}
\mathbf{H}^{0}_\mathbf{xx}  & \mathbf{H}^{1}_\mathbf{xx} & \cdots         & \mathbf{H}^{Q-1}_\mathbf{xx} \\
\mathbf{H}^{1}_\mathbf{xx}  & \mathbf{H}^{0}_\mathbf{xx} & \ddots         & \vdots           \\ 
\vdots           & \ddots         & \ddots         & \mathbf{H}^{1}_\mathbf{xx}   \\
\mathbf{H}^{Q-1}_\mathbf{xx} & \cdots         & \mathbf{H}^{1}_\mathbf{xx} & \mathbf{H}^{0}_\mathbf{xx}                
\end{bmatrix}_{N \times N} \: .
\label{eq:BTTB_Hxx}
\end{equation}
And each diagonal of the blocks are represented by $P \times P$ elements $h^{q}_{p}$, $p = 0, \dots, P - 1$:
\begin{equation}
\mathbf{H}^{q}_\mathbf{xx} = \{h^{q}_p\} = \begin{bmatrix}
h^{q}_{0}   & h^{q}_{1} & \cdots    & h^{q}_{P-1} \\
h^{q}_{1}   & h^{q}_{0} & \ddots    & \vdots           \\ 
\vdots      & \ddots    & \ddots    & h^{q}_{1}   \\
h^{q}_{P-1} & \cdots    & h^{q}_{1} & h^{q}_{0}                 
\end{bmatrix}_{P \times P} \: .
\label{eq:Hxx_block}
\end{equation}
In a $x$-\textit{oriented grid} $Q = N_{x}$, $P = N_{y}$ and $q$ and $p$ can be defined by the functions:
\begin{equation}
q(i, j) = \; \mid l(i) - l(j) \mid
\label{eq:Hxx-q-x-oriented}
\end{equation}
and
\begin{equation}
p(i, j) = \; \mid k(i) - k(j) \mid \quad ,
\label{eq:Hxx-p-x-oriented}
\end{equation}
where $l(i)$ and $l(j)$ are defined by equation \ref{eq:l-x-oriented} 
and $k(i)$ and $k(j)$ are defined by equation \ref{eq:k-x-oriented}.
For $y$-oriented grids, $Q = N_{x}$, $P = N_{y}$ and the block indices
$q$ and $p$ are defined, respectively, by the following integer functions 
of the matrix indices $i$ and $j$:
\begin{equation}
q(i, j) = \; \mid k(i) - k(j) \mid 
\label{eq:Hxx-q-y-oriented}
\end{equation}
and
\begin{equation}
p(i, j) = \; \mid l(i) - l(j) \mid \quad ,
\label{eq:Hxx-p-y-oriented}
\end{equation}
This struture can also describe matrices $\mathbf{H_{yy}}$ and $\mathbf{H_{zz}}$ in the same manner and they are identical to the structure of the gravity sensitivity matrix from \cite{takahashi2020convolutional}.

%======================================================================================
\subsection{Structure of the components matrices $\mathbf{H_{xy}}$}
%======================================================================================

By substituting equations \ref{eq:xi} and \ref{eq:yi} in equation \ref{eq:Hi}, we can also describe the elements of $\mathbf{H_{xy}}$, as:
\begin{equation}
	h^{xy}_{ij} = \frac{3 (\Delta k_{ij} \, \Delta x )(\Delta l_{ij} \, \Delta y )}{\left[ 
		\left( \Delta k_{ij} \, \Delta x \right)^{2} + 
		\left( \Delta l_{ij} \, \Delta y \right)^{2} + 
		\left( \Delta z \right)^{2} \right]^{\frac{5}{2}}} \: ,
	\label{eq:hxy_mag}
\end{equation}

The component $\mathbf{H_{xy}}$ (equation \ref{eq:hxy_mag}) of matrix $\mathbf{H}$ (equation \ref{eq:Hi}) are skew symmetric-Block-Toeplitz skew symmetric-Toeplitz-Block matrices. This means that $\mathbf{H_{xy}}$ is Toeplitz and skew symmetric by its blocks and each of the blocks are skew symmetric Toeplitz matrices. 
This way, matrix $\mathbf{H_{xy}}$ can be described by the \textit{block indice} $q$ that represent the block diagonals of this matrix as a grid of $Q \times Q$ blocks $\mathbf{H}^{q}_\mathbf{xy}$, $q = -Q + 1, \dots, 0, \dots, Q - 1$:
\begin{equation}
	\mathbf{H_{xy}} = \begin{bmatrix}
		\mathbf{H}^{0}_\mathbf{xy}  & \mathbf{H}^{-1}_\mathbf{xy} & \cdots         & \mathbf{H}^{-Q+1}_\mathbf{xy} \\
		\mathbf{H}^{1}_\mathbf{xy}  & \mathbf{H}^{0}_\mathbf{xy} & \ddots         & \vdots           \\ 
		\vdots           & \ddots         & \ddots         & \mathbf{H}^{-1}_\mathbf{xy}   \\
		\mathbf{H}^{Q-1}_\mathbf{xy} & \cdots         & \mathbf{H}^{1}_\mathbf{xy} & \mathbf{H}^{0}_\mathbf{xy}                
	\end{bmatrix}_{N \times N} \: .
	\label{eq:BTTB_Hxy}
\end{equation}
And each diagonal of the blocks are represented by $P \times P$ elements $h^{q}_{p}$, $p = -P + 1, \dots, 0, \dots, P - 1$:
\begin{equation}
	\mathbf{H}^{q}_\mathbf{xy} =  \{h^{q}_p\} = \begin{bmatrix}
		h^{q}_{0}   & h^{q}_{-1} & \cdots    & h^{q}_{-P+1} \\
		h^{q}_{1}   & h^{q}_{0} & \ddots    & \vdots           \\ 
		\vdots      & \ddots    & \ddots    & h^{q}_{-1}   \\
		h^{q}_{P-1} & \cdots    & h^{q}_{1} & h^{q}_{0}                 
	\end{bmatrix}_{P \times P} \: .
	\label{eq:Hxy_block}
\end{equation}
In a $x$-\textit{oriented grid} $Q = N_{x}$, $P = N_{y}$ and $q$ and $p$ can be defined by the functions:
\begin{equation}
	q(i, j) = \; l(i) - l(j) 
	\label{eq:Hxy-q-x-oriented}
\end{equation}
and
\begin{equation}
	p(i, j) = \; k(i) - k(j) \quad ,
	\label{eq:Hxy-p-x-oriented}
\end{equation}
where $l(i)$ and $l(j)$ are defined by equation \ref{eq:l-x-oriented} 
and $k(i)$ and $k(j)$ are defined by equation \ref{eq:k-x-oriented}.
For $y$-oriented grids, $Q = N_{x}$, $P = N_{y}$ and the block indices
$q$ and $p$ are defined, respectively, by the following integer functions 
of the matrix indices $i$ and $j$:
\begin{equation}
	q(i, j) = \;  k(i) - k(j)  
	\label{eq:Hxy-q-y-oriented}
\end{equation}
and
\begin{equation}
	p(i, j) = \;  l(i) - l(j)  \quad ,
	\label{eq:Hxy-p-y-oriented}
\end{equation}
Important to clarify that in this case, as a skew symmetric matrix, the values of oposing diagonals have oposing signals, e.g., $\mathbf{H}^{-1}_\mathbf{xy} = -\mathbf{H}^{1}_\mathbf{xy}$ and $h^{q}_{-1} = -h^{q}_{1} $.

%======================================================================================
\subsection{Structure of the components matrices $\mathbf{H_{xz}}$}
%======================================================================================

By substituting equations \ref{eq:xi} and \ref{eq:yi} in equation \ref{eq:Hi}, the elements of $\mathbf{H_{xz}}$, are given by:
\begin{equation}
	h^{xz}_{ij} = \frac{3 (\Delta k_{ij} \, \Delta x)(\Delta z)}{\left[ 
		\left( \Delta k_{ij} \, \Delta x \right)^{2} + 
		\left( \Delta l_{ij} \, \Delta y \right)^{2} + 
		\left( \Delta z \right)^{2} \right]^{\frac{5}{2}}} \: ,
	\label{eq:hxz_mag}
\end{equation}

The component $\mathbf{H_{xz}}$ (equation \ref{eq:hxz_mag}) of matrix $\mathbf{H}$ (equation \ref{eq:Hi}) are skew symmetric-Block-Toeplitz symmetric-Toeplitz-Block matrices. This means that $\mathbf{H_{xz}}$ is Toeplitz and skew symmetric by its blocks and each of the blocks are symmetric Toeplitz matrices. 
Thus, matrix $\mathbf{H_{xz}}$ can be described by the \textit{block indice} $q$ that represent the block diagonals of this matrix as a grid of $Q \times Q$ blocks $\mathbf{H}^{q}_\mathbf{xz}$, $q = -Q + 1, \dots, 0, \dots, Q - 1$:
\begin{equation}
	\mathbf{H_{xz}} = \begin{bmatrix}
		\mathbf{H}^{0}_\mathbf{xz}  & \mathbf{H}^{-1}_\mathbf{xz} & \cdots         & \mathbf{H}^{-Q+1}_\mathbf{xz} \\
		\mathbf{H}^{1}_\mathbf{xz}  & \mathbf{H}^{0}_\mathbf{xz} & \ddots         & \vdots           \\ 
		\vdots           & \ddots         & \ddots         & \mathbf{H}^{-1}_\mathbf{xz}   \\
		\mathbf{H}^{Q-1}_\mathbf{xz} & \cdots         & \mathbf{H}^{1}_\mathbf{xz} & \mathbf{H}^{0}_\mathbf{xz}                
	\end{bmatrix}_{N \times N} \: .
	\label{eq:BTTB_Hxz}
\end{equation}
And each diagonal of the blocks are represented by $P \times P$ elements $h^{q}_{p}$, $p = 0, \dots, P - 1$:
\begin{equation}
	\mathbf{H}^{q}_\mathbf{xz} =  \{h^{q}_p\} = \begin{bmatrix}
		h^{q}_{0}   & h^{q}_{1} & \cdots    & h^{q}_{P-1} \\
		h^{q}_{1}   & h^{q}_{0} & \ddots    & \vdots           \\ 
		\vdots      & \ddots    & \ddots    & h^{q}_{1}   \\
		h^{q}_{P-1} & \cdots    & h^{q}_{1} & h^{q}_{0}                 
	\end{bmatrix}_{P \times P} \: .
	\label{eq:Hxz_block}
\end{equation}
In a $x$-\textit{oriented grid} $Q = N_{x}$, $P = N_{y}$ and $q$ and $p$ can be defined by the functions:
\begin{equation}
	q(i, j) = \; l(i) - l(j) 
	\label{eq:Hxz-q-x-oriented}
\end{equation}
and
\begin{equation}
	p(i, j) = \; \mid k(i) - k(j) \mid \quad ,
	\label{eq:Hxz-p-x-oriented}
\end{equation}
where $l(i)$ and $l(j)$ are defined by equation \ref{eq:l-x-oriented} 
and $k(i)$ and $k(j)$ are defined by equation \ref{eq:k-x-oriented}.
For $y$-oriented grids, $Q = N_{x}$, $P = N_{y}$ and the block indices
$q$ and $p$ are defined, respectively, by the following integer functions 
of the matrix indices $i$ and $j$:
\begin{equation}
	q(i, j) = \;  k(i) - k(j)  
	\label{eq:Hxz-q-y-oriented}
\end{equation}
and
\begin{equation}
	p(i, j) = \; \mid l(i) - l(j) \mid \quad ,
	\label{eq:Hxz-p-y-oriented}
\end{equation}
In this case as a skew symmetric matrix by blocks, the values of oposing diagonals blocks have oposing signals, e.g., $\mathbf{H}^{-1}_\mathbf{xz} = -\mathbf{H}^{1}_\mathbf{xz}$ but each block is a symmetric matrix.

%======================================================================================
\subsection{Structure of the components matrices $\mathbf{H_{yz}}$}
%======================================================================================

Finally, by substituting equations \ref{eq:xi} and \ref{eq:yi} in equation \ref{eq:Hi}, we can also describe the elements of $\mathbf{H_{yz}}$, as:
\begin{equation}
	h^{yz}_{ij} = \frac{3 (\Delta l_{ij} \, \Delta y )(\Delta z)}{\left[ 
		\left( \Delta k_{ij} \, \Delta x \right)^{2} + 
		\left( \Delta l_{ij} \, \Delta y \right)^{2} + 
		\left( \Delta z \right)^{2} \right]^{\frac{5}{2}}} \: ,
	\label{eq:hyz_mag}
\end{equation}

The component $\mathbf{H_{yz}}$ (equation \ref{eq:hyz_mag}) of matrix $\mathbf{H}$ (equation \ref{eq:Hi}) are symmetric-Block-Toeplitz skew symmetric-Toeplitz-Block matrices. This means that $\mathbf{H_{yz}}$ is Toeplitz and symmetric by its blocks and each of the blocks are skew symmetric Toeplitz matrices.
Thus, matrix $\mathbf{H_{yz}}$ can be described by the \textit{block indice} $q$ that represent the block diagonals of this matrix as a grid of $Q \times Q$ blocks $\mathbf{H}^{q}_\mathbf{yz}$, $q = 0, \dots, Q - 1$:
\begin{equation}
	\mathbf{H_{yz}} = \begin{bmatrix}
		\mathbf{H}^{0}_\mathbf{yz}  & \mathbf{H}^{1}_\mathbf{yz} & \cdots         & \mathbf{H}^{Q-1}_\mathbf{yz} \\
		\mathbf{H}^{1}_\mathbf{yz}  & \mathbf{H}^{0}_\mathbf{yz} & \ddots         & \vdots           \\ 
		\vdots           & \ddots         & \ddots         & \mathbf{H}^{1}_\mathbf{yz}   \\
		\mathbf{H}^{Q-1}_\mathbf{yz} & \cdots         & \mathbf{H}^{1}_\mathbf{yz} & \mathbf{H}^{0}_\mathbf{yz}                
	\end{bmatrix}_{N \times N} \: .
	\label{eq:BTTB_Hyz}
\end{equation}
And each diagonal of the blocks are represented by $P \times P$ elements $h^{q}_{p}$, $p = -P + 1, \dots, 0, \dots, P - 1$:
\begin{equation}
	\mathbf{H}^{q}_\mathbf{yz} =  \{h^{q}_p\} = \begin{bmatrix}
		h^{q}_{0}   & h^{q}_{-1} & \cdots    & h^{q}_{-P+1} \\
		h^{q}_{1}   & h^{q}_{0} & \ddots    & \vdots           \\ 
		\vdots      & \ddots    & \ddots    & h^{q}_{-1}   \\
		h^{q}_{P-1} & \cdots    & h^{q}_{1} & h^{q}_{0}                 
	\end{bmatrix}_{P \times P} \: .
	\label{eq:Hyz_block}
\end{equation}
In a $x$-\textit{oriented grid} $Q = N_{x}$, $P = N_{y}$ and $q$ and $p$ can be defined by the functions:
\begin{equation}
	q(i, j) = \; \mid l(i) - l(j) \mid
	\label{eq:Hyz-q-x-oriented}
\end{equation}
and
\begin{equation}
	p(i, j) = \; k(i) - k(j) \quad ,
	\label{eq:Hyz-p-x-oriented}
\end{equation}
where $l(i)$ and $l(j)$ are defined by equation \ref{eq:l-x-oriented} 
and $k(i)$ and $k(j)$ are defined by equation \ref{eq:k-x-oriented}.
For $y$-oriented grids, $Q = N_{x}$, $P = N_{y}$ and the block indices
$q$ and $p$ are defined, respectively, by the following integer functions 
of the matrix indices $i$ and $j$:
\begin{equation}
	q(i, j) = \; \mid k(i) - k(j) \mid
	\label{eq:Hyz-q-y-oriented}
\end{equation}
and
\begin{equation}
	p(i, j) = \; l(i) - l(j) \quad ,
	\label{eq:Hyz-p-y-oriented}
\end{equation}
Being a symmetric matrix by blocks, the values of $\mathbf{H_{yz}}$ from oposing diagonals blocks are equal, but each block have skew symmetric oposing diagonals, i.e., $h^{q}_{-1} = - h^{q}_{1}$.

%======================================================================================
\subsection{CGLS matrix-vector substitution}
%======================================================================================

As pointed earlier in this work, the main improvement inside the CGLS method (Algorithm \ref{al:cgls-algorithm}) for estimating the parameter vector $\hat{\mathbf{p}}$ (equation \ref{eq:estimated-p-parameter-space}) is to substitute the matrix-vector multiplication $\mathbf{A}^{\top} \mathbf{s}^{(0)}$ out of the loop and the two matrix-vector multiplications inside the loop at steps 3 an 6, $\mathbf{A} \, \mathbf{c}^{(it)}$ and $\mathbf{A}^{\top} \, \mathbf{s}^{(it + 1)}$, that is necessary at each iteration and takes most of its runtime.

Our method consists in calculating the six first columns of the second derivatives of $\mathbf{H}$ (equation \ref{eq:Hi}) and embbed them into the first six columns of the block-circulant circulant-block (BCCB) matrices related to the $\mathbf{H}$ components. Thus, it is possible to calculate the first column of the BCCB matrix embbeded from matrix $\mathbf{A}$ (equation \ref{eq:aij_mag}) by multiplying each component with its respective constants and summing as shown in equation \ref{eq:aij_mag_expand}. In \cite{takahashi2020convolutional}, Appendix A, the authors demonstrated in details how to transform a symmetric BTTB matrix into a BCCB matrix $\mathbf{C}$. The process here is the same and that work can be referenced to achieve the same results.

A new auxuliary linear system is constructed to carry the matrix-vector product:
\begin{equation}
\mathbf{w} = \mathbf{C} \mathbf{v} \: ,
\label{eq:w_Cv}
\end{equation}
where
\begin{equation}
\mathbf{w} = \begin{bmatrix}
\mathbf{w}_{0} \\
\vdots \\
\mathbf{w}_{Q - 1} \\
\mathbf{0}_{2N \times 1}
\end{bmatrix}_{4N \times 1} \quad ,
\label{eq:w-vector}
\end{equation}
\begin{equation}
\mathbf{w}_{q} = \begin{bmatrix}
\mathbf{d}_{q}(\mathbf{p}) \\
\mathbf{0}_{P \times 1}
\end{bmatrix}_{2P \times 1}
\label{eq:wq-vector} \quad ,
\end{equation}
\begin{equation}
\mathbf{v} = \begin{bmatrix}
\mathbf{v}_{0} \\
\vdots \\
\mathbf{v}_{Q - 1} \\
\mathbf{0}_{2N \times 1}
\end{bmatrix}_{4N \times 1} \quad ,
\label{eq:v-vector}
\end{equation}
and
\begin{equation}
\mathbf{v}_{q} = \begin{bmatrix}
\mathbf{p}_{q} \\
\mathbf{0}_{P \times 1}
\end{bmatrix}_{2P \times 1}
\label{eq:vq-vector} \quad ,
\end{equation}
where $\mathbf{C}$ (equation \ref{eq:w_Cv}) is a $4N \times 4N$ non-symmetric (BCCB) resulted from transforming $\mathbf{A}$ (equation \ref{eq:aij_mag}). Without having to calculate the whole BCCB matrix, its first column can be used to carry the multiplication of this new system (equation \ref{eq:w_Cv}). Appendix A and C in \cite{takahashi2020convolutional} shows how to use the 2D-FFT to compute the eigenvalues of matrix $\mathbf{C}$, store in a $2Q \times 2P$ matrix using the $vec$-operator and to carry the matrix-vector product. Denoting matrix $\mathbf{L}$ as the eigenvalues matrix follows:
\begin{equation}
	\mathbf{F}_{2Q}^{\ast} \left[ 
	\mathbf{L} \circ \left(\mathbf{F}_{2Q} \, \mathbf{V} \, \mathbf{F}_{2P} \right) 
	\right] \mathbf{F}_{2P}^{\ast} = \mathbf{W} \: ,
	\label{eq:DFT-system}
\end{equation}
where the symbol ``$\circ$'' references the Hadamard product, i.e., a element-wise complex multiplication between the eingenvalues and the 2D-FFT of the matrix rearranged along the rows of the parameters $\mathbf{V}$ (equation \ref{eq:v-vector}) using the same $vec$-operator. The resulting inverse 2D-FFT denoted by $\mathbf{F}_{2Q}^{\ast}  \otimes \mathbf{F}_{2P}^{\ast}$ is also a $2Q \times 2P$ matrix ($\mathbf{W}$) that can be rearranged to the predicted data vector $\mathbf{d}(\hat{\mathbf{p}})$ size $N$.

%======================================================================================
\subsection{Computational performance}
%======================================================================================

To compare the efficiency of our algorithm we will use a numerical approach and calculate the floating-point operations (\emph{flops}), i.e., count the number of mathematical operations necessary to complete the estimative of parameter vector $\mathbf{\hat{p}}$ of the normal equations (equation \ref{eq:estimated-p-parameter-space}) and both the CGLS methods (algorithm \ref{al:cgls-algorithm}) for calculating the matrix-vector product by its standart way and our approach.

The \emph{flops} needed to solve the linear system in equation \ref{eq:estimated-p-parameter-space} using the Cholesky factorization is:
\begin{equation}
f_{classical} =  \dfrac{7}{3} N^{3} + 6 N^{2}\: ,
\label{eq:flops-normal-cholesky}
\end{equation}
where $N$ is the total number of observation points and also the size of estimated parameter vector $\mathbf{\hat{p}}$.

For the more efficient CGLS algorithm the estimative can be done in:
\begin{equation}
f_{cgls} =  2 N^{2} + it \, (4 N^{2} + 12 N) \: .
\label{eq:flops-cgls}
\end{equation}
However, our approach reduces further to:
\begin{equation}
f_{ours} =  \kappa  \, 16 N \log_2(4 N) + 24 N + it \, (\kappa  \, 16 N \log_2 (4 N) + 60 N) \: ,
\label{eq:flops-cgls-bccb}
\end{equation}
where $\kappa$ depends on the FFT algorithm. By default, in this work we will use $\kappa = 5$ for the \emph{radix-2} algorithm \citep{vanloan1992}.

Figure \ref{fig:flops} shows a comparative between the methods varying the number of observation points up to $1,000,000$, where it is possible to observe a reduction of $10^7$ orders of magnitude to estimate parameter vector $\mathbf{\hat{p}}$ in relation to the non-iterative classical method and $10^3$ orders of magnitude in relation to the standart CGLS algorithm using $50$ iterations. A more detailed, step by step, flops count of the classical and CGLS algorithm can be found in Appendix A.

In figure \ref{fig:solve_time} we show the time necessary to construct matrix $\mathbf{A}$ (equation \ref{eq:aij_mag}) and solve the linear system up to $10,000$ points of observation. With this dataset the classical method takes more than sixty-three seconds, the CGLS more than twelve seconds, while our method takes only half a second. The cpu used for this test was a intel core i7-7700HQ@2.8GHz.

In figure \ref{fig:sources_time} a comparison between the time to complete the task to calculate the first column of the BCCB matrix embbeded from the from $\mathbf{A}$ (equation \ref{eq:aij_mag}) by using only one equivalent source, i.e., calculating all six first column of the second derivatives matrices from $\mathbf{H}$ (equation \ref{eq:Hi}) and using four equivalent sources to calculate the four necessary columns from the non-symmetric matrix $\mathbf{A}$ (equation \ref{eq:aij_mag}). Although, very similar in time, with one source a small advantage can be observed as the number of data $N$ increases and goes beyond $N = 200,000$. This test was done from $N = 10,000$ to $N = 700,000$ with increases of $5,625$ observation points.

In Table \ref{tab:RAM-usage} there is comparison between how much RAM memory is adressed to store the sensitivity matrix for each of the methods. The classical approach and the CGLS have to store the whole matrix $\mathbf{A}$ (equation \ref{eq:aij_mag}), this means that a dataset  with for example $N = 10,000$ observation points, the sensitivity matrix has $N^2 = 100,000,000$ elements and takes approximately $763$ Megabytes of memory (8 bytes per element). For our method, it is necessary to store the first six columns of each of the components from matrix $\mathbf{H}$ (equation \ref{eq:Hi}) embedded into the BCCB matrices. With the same dataset $N = 10,000$ it needs $1.831$ Megabytes. After completing the steps to store the eigenvalues of matrix $\mathbf{C}$ (equation \ref{eq:w_Cv}) it takes only $0.6104$ Megabytes. Here, we are considering 16 bytes per element as the eigenvalues are complex numbers resulting from the 2D FFT. For a bigger dataset as $N = 1,000,000$ the amount of RAM necessary goes to $7,629,395$, $183.096$ and $61.035$ Megabytes, respectively, showing the necessity to find improved and efficient methods for the equivalent layer technique as the one presented in this work. We remember that throughout our work we are always considering $N = M$.









